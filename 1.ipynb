{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqmFUb57Eg+uLcD0jcxQ4m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotianbipin/Conversation-Management-Classification/blob/main/1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFAO98COyaZZ"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Install and imports\n",
        "!pip install --quiet openai requests\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "from openai import OpenAI  # Groq uses OpenAI-compatible client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set API key"
      ],
      "metadata": {
        "id": "nW0LZmgZz5Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 2: Configure Groq API key using Colab Secrets (userdata.get)\n",
        "# =============================================================================\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load Groq API key from Colab Secrets\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')  # <-- use the exact name of your secret\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise RuntimeError(\n",
        "        \"GROQ_API_KEY not found in Colab secrets. \"\n",
        "        \"Go to the left sidebar > Secrets (🔒) and add it.\"\n",
        "    )\n",
        "\n",
        "# Optional: verify that key is loaded (only first 6 characters shown)\n",
        "print(\"✅ GROQ_API_KEY loaded:\", GROQ_API_KEY[:6] + \"****\")\n",
        "\n",
        "# Initialize OpenAI-compatible Groq client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=GROQ_API_KEY\n",
        ")\n",
        "\n",
        "# Quick connection test using an active Groq model\n",
        "try:\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",  # Active Groq model\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Hello, test connection\"}],\n",
        "        max_tokens=40\n",
        "    )\n",
        "    print(\"✅ Groq API connection successful!\")\n",
        "    print(\"Test response:\", resp.choices[0].message.content.strip())\n",
        "except Exception as e:\n",
        "    print(\"❌ Connection failed:\", e)\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku8XyPNLz9cD",
        "outputId": "d5653b51-ba59-4e46-a7f8-879de498b5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GROQ_API_KEY loaded: gsk_CH****\n",
            "✅ Groq API connection successful!\n",
            "Test response: The connection seems to be working properly. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConversationManager class (Task 1: history, truncation, periodic summarization)"
      ],
      "metadata": {
        "id": "Flb6MH3i1763"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: ConversationManager\n",
        "class ConversationManager:\n",
        "    \"\"\"\n",
        "    Manage conversation history, truncation and periodic summarization.\n",
        "    - Uses a counter to trigger summarization every k messages.\n",
        "    - Summaries replace older history per design.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, client: OpenAI,\n",
        "                 summarization_model: str = \"llama-3.1-8b-instant\",\n",
        "                 summary_max_tokens: int = 200):\n",
        "        self.client = client\n",
        "        self.model = summarization_model\n",
        "        self.summary_max_tokens = summary_max_tokens\n",
        "\n",
        "        self.conversation_history: List[Dict[str, Any]] = []\n",
        "        self._message_counter = 0        # increments on add_message\n",
        "        self.latest_summary: Optional[str] = None\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        msg = {\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        self.conversation_history.append(msg)\n",
        "        self._message_counter += 1\n",
        "\n",
        "    def truncate_by_turns(self, max_turns: int) -> List[Dict[str, Any]]:\n",
        "        if max_turns <= 0:\n",
        "            return []\n",
        "        return self.conversation_history[-max_turns:]\n",
        "\n",
        "    def truncate_by_length(self, max_chars: int) -> List[Dict[str, Any]]:\n",
        "        total = 0\n",
        "        kept = []\n",
        "        # iterate from most recent backwards\n",
        "        for m in reversed(self.conversation_history):\n",
        "            c_len = len(m[\"content\"])\n",
        "            if total + c_len <= max_chars:\n",
        "                kept.insert(0, m)\n",
        "                total += c_len\n",
        "            else:\n",
        "                break\n",
        "        return kept\n",
        "\n",
        "    def _conversation_text(self, messages: Optional[List[Dict[str,Any]]] = None) -> str:\n",
        "        messages = messages if messages is not None else self.conversation_history\n",
        "        lines = []\n",
        "        for m in messages:\n",
        "            role = m[\"role\"].capitalize()\n",
        "            lines.append(f\"{role}: {m['content']}\")\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def summarize(self, messages: Optional[List[Dict[str,Any]]] = None) -> str:\n",
        "        \"\"\"\n",
        "        Call the LLM to produce a concise summary of messages.\n",
        "        Returns summary string or raises Exception.\n",
        "        \"\"\"\n",
        "        messages = messages if messages is not None else self.conversation_history\n",
        "        if not messages:\n",
        "            return \"\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a helpful assistant. Provide a concise summary (under 200 words) \"\n",
        "            \"that captures key points, decisions and actionable items from the conversation below.\\n\\n\"\n",
        "            + self._conversation_text(messages)\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            resp = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\":\"user\", \"content\": prompt}],\n",
        "                max_tokens=self.summary_max_tokens,\n",
        "                temperature=0.2\n",
        "            )\n",
        "            summary = resp.choices[0].message.content.strip()\n",
        "            self.latest_summary = summary\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            # return error string so caller can display\n",
        "            return f\"Summarization failed: {e}\"\n",
        "\n",
        "    def periodic_summarization(self, k: int, keep_recent_half_k: bool = True) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        If _message_counter >= k, summarize all history, replace history with:\n",
        "        [system summary message] + recent messages (kept length is k//2 if keep_recent_half_k).\n",
        "        Returns the summary string if summarization occurred, else None.\n",
        "        \"\"\"\n",
        "        if k <= 0:\n",
        "            return None\n",
        "\n",
        "        if self._message_counter >= k:\n",
        "            # summarize entire history\n",
        "            summary_text = self.summarize(None)\n",
        "\n",
        "            # prepare summary system message\n",
        "            summary_msg = {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"[SUMMARY] {summary_text}\",\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            # keep recent messages after summarization\n",
        "            keep_count = (k // 2) if keep_recent_half_k else 0\n",
        "            recent = self.conversation_history[-keep_count:] if keep_count > 0 else []\n",
        "\n",
        "            # replace history\n",
        "            self.conversation_history = [summary_msg] + recent\n",
        "\n",
        "            # reset counter\n",
        "            self._message_counter = 0\n",
        "\n",
        "            return summary_text\n",
        "        return None\n",
        "\n",
        "    def get_conversation_with_options(self, max_turns: Optional[int] = None,\n",
        "                                      max_chars: Optional[int] = None) -> List[Dict[str,Any]]:\n",
        "        if max_turns is not None:\n",
        "            return self.truncate_by_turns(max_turns)\n",
        "        if max_chars is not None:\n",
        "            return self.truncate_by_length(max_chars)\n",
        "        return list(self.conversation_history)  # copy\n",
        "\n",
        "    def display(self, messages: Optional[List[Dict[str,Any]]] = None):\n",
        "        msgs = messages if messages is not None else self.conversation_history\n",
        "        if not msgs:\n",
        "            print(\"[No conversation messages]\")\n",
        "            return\n",
        "        print(\"=\"*60)\n",
        "        print(\"CONVERSATION HISTORY\")\n",
        "        print(\"=\"*60)\n",
        "        for i, m in enumerate(msgs, 1):\n",
        "            emoji = \"🤖\" if m[\"role\"] == \"assistant\" else \"👤\" if m[\"role\"] == \"user\" else \"📋\"\n",
        "            print(f\"{i}. {emoji} {m['role'].upper()}: {m['content']}\")\n",
        "            if \"timestamp\" in m:\n",
        "                print(f\"   ⏰ {m['timestamp']}\")\n",
        "            print(\"-\"*40)\n"
      ],
      "metadata": {
        "id": "fyf2sJYg1_jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrate Task 1 (samples, truncation, periodic summarization)"
      ],
      "metadata": {
        "id": "rHBLJCja2Dkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Demonstration of Task 1\n",
        "conv_mgr = ConversationManager(client)\n",
        "\n",
        "# feed sample conversation\n",
        "samples = [\n",
        "    (\"user\", \"Hello, I'm looking for information about your data science course.\"),\n",
        "    (\"assistant\", \"We have a 6-month course covering Python, ML, stats, visualization.\"),\n",
        "    (\"user\", \"What's the cost and schedule?\"),\n",
        "    (\"assistant\", \"Cost is $2,999; we offer monthly instalments. Schedule is weekday evenings.\"),\n",
        "    (\"user\", \"Do you provide a trial session?\"),\n",
        "    (\"assistant\", \"Yes — 2-hour free trial available next week.\"),\n",
        "    (\"user\", \"Great, please schedule me and tell me payment options.\"),\n",
        "]\n",
        "\n",
        "for role, content in samples:\n",
        "    conv_mgr.add_message(role, content)\n",
        "\n",
        "# display full conversation\n",
        "print(\"\\n--- Full conversation ---\")\n",
        "conv_mgr.display()\n",
        "\n",
        "# Truncation examples\n",
        "print(\"\\n--- Truncation: last 4 messages ---\")\n",
        "last4 = conv_mgr.get_conversation_with_options(max_turns=4)\n",
        "conv_mgr.display(last4)\n",
        "\n",
        "print(\"\\n--- Truncation: max 300 chars ---\")\n",
        "by_chars = conv_mgr.get_conversation_with_options(max_chars=300)\n",
        "conv_mgr.display(by_chars)\n",
        "\n",
        "# Periodic summarization example: summarize every 3 messages\n",
        "print(\"\\n--- Periodic Summarization Demo (k=3) ---\")\n",
        "# Add more messages to trigger summarization twice\n",
        "more = [\n",
        "    (\"user\", \"I'm John Doe, 28, located in New York.\"),\n",
        "    (\"assistant\", \"Thanks John. Do you want syllabus details?\"),\n",
        "    (\"user\", \"Yes, email me the syllabus at john.doe@example.com.\"),\n",
        "    (\"assistant\", \"Done. Please check your inbox.\"),\n",
        "    (\"user\", \"Also what's the refund policy?\"),\n",
        "    (\"assistant\", \"You can request refund within 14 days.\")\n",
        "]\n",
        "\n",
        "for role, content in more:\n",
        "    conv_mgr.add_message(role, content)\n",
        "    summary = conv_mgr.periodic_summarization(k=3)\n",
        "    if summary:\n",
        "        print(\"\\n📋 SUMMARY GENERATED:\")\n",
        "        print(summary)\n",
        "        print(\"-\"*40)\n",
        "\n",
        "print(\"\\n--- Final conversation state ---\")\n",
        "conv_mgr.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d6oCc-G2JAp",
        "outputId": "84bb7d82-e961-4d45-efb1-e03b261fdcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Full conversation ---\n",
            "============================================================\n",
            "CONVERSATION HISTORY\n",
            "============================================================\n",
            "1. 👤 USER: Hello, I'm looking for information about your data science course.\n",
            "   ⏰ 2025-09-14T10:50:11.211458\n",
            "----------------------------------------\n",
            "2. 🤖 ASSISTANT: We have a 6-month course covering Python, ML, stats, visualization.\n",
            "   ⏰ 2025-09-14T10:50:11.211480\n",
            "----------------------------------------\n",
            "3. 👤 USER: What's the cost and schedule?\n",
            "   ⏰ 2025-09-14T10:50:11.211485\n",
            "----------------------------------------\n",
            "4. 🤖 ASSISTANT: Cost is $2,999; we offer monthly instalments. Schedule is weekday evenings.\n",
            "   ⏰ 2025-09-14T10:50:11.211489\n",
            "----------------------------------------\n",
            "5. 👤 USER: Do you provide a trial session?\n",
            "   ⏰ 2025-09-14T10:50:11.212132\n",
            "----------------------------------------\n",
            "6. 🤖 ASSISTANT: Yes — 2-hour free trial available next week.\n",
            "   ⏰ 2025-09-14T10:50:11.212146\n",
            "----------------------------------------\n",
            "7. 👤 USER: Great, please schedule me and tell me payment options.\n",
            "   ⏰ 2025-09-14T10:50:11.212150\n",
            "----------------------------------------\n",
            "\n",
            "--- Truncation: last 4 messages ---\n",
            "============================================================\n",
            "CONVERSATION HISTORY\n",
            "============================================================\n",
            "1. 🤖 ASSISTANT: Cost is $2,999; we offer monthly instalments. Schedule is weekday evenings.\n",
            "   ⏰ 2025-09-14T10:50:11.211489\n",
            "----------------------------------------\n",
            "2. 👤 USER: Do you provide a trial session?\n",
            "   ⏰ 2025-09-14T10:50:11.212132\n",
            "----------------------------------------\n",
            "3. 🤖 ASSISTANT: Yes — 2-hour free trial available next week.\n",
            "   ⏰ 2025-09-14T10:50:11.212146\n",
            "----------------------------------------\n",
            "4. 👤 USER: Great, please schedule me and tell me payment options.\n",
            "   ⏰ 2025-09-14T10:50:11.212150\n",
            "----------------------------------------\n",
            "\n",
            "--- Truncation: max 300 chars ---\n",
            "============================================================\n",
            "CONVERSATION HISTORY\n",
            "============================================================\n",
            "1. 🤖 ASSISTANT: We have a 6-month course covering Python, ML, stats, visualization.\n",
            "   ⏰ 2025-09-14T10:50:11.211480\n",
            "----------------------------------------\n",
            "2. 👤 USER: What's the cost and schedule?\n",
            "   ⏰ 2025-09-14T10:50:11.211485\n",
            "----------------------------------------\n",
            "3. 🤖 ASSISTANT: Cost is $2,999; we offer monthly instalments. Schedule is weekday evenings.\n",
            "   ⏰ 2025-09-14T10:50:11.211489\n",
            "----------------------------------------\n",
            "4. 👤 USER: Do you provide a trial session?\n",
            "   ⏰ 2025-09-14T10:50:11.212132\n",
            "----------------------------------------\n",
            "5. 🤖 ASSISTANT: Yes — 2-hour free trial available next week.\n",
            "   ⏰ 2025-09-14T10:50:11.212146\n",
            "----------------------------------------\n",
            "6. 👤 USER: Great, please schedule me and tell me payment options.\n",
            "   ⏰ 2025-09-14T10:50:11.212150\n",
            "----------------------------------------\n",
            "\n",
            "--- Periodic Summarization Demo (k=3) ---\n",
            "\n",
            "📋 SUMMARY GENERATED:\n",
            "Here's a concise summary of the conversation:\n",
            "\n",
            "**Key Points:**\n",
            "\n",
            "- The data science course is 6 months long, covering Python, Machine Learning, statistics, and visualization.\n",
            "- The course cost is $2,999, with the option for monthly instalments.\n",
            "- The course schedule is weekday evenings.\n",
            "\n",
            "**Decisions:**\n",
            "\n",
            "- John Doe has expressed interest in the course and would like to schedule a trial session.\n",
            "- The trial session is a 2-hour free session available next week.\n",
            "\n",
            "**Actionable Items:**\n",
            "\n",
            "- Schedule a 2-hour free trial session for John Doe next week.\n",
            "- Provide payment options for the course, including monthly instalments.\n",
            "- Confirm the course details with John Doe, including the schedule and cost.\n",
            "----------------------------------------\n",
            "\n",
            "📋 SUMMARY GENERATED:\n",
            "**Summary:**\n",
            "\n",
            "Key Points:\n",
            "- The 6-month data science course covers Python, Machine Learning, statistics, and visualization.\n",
            "- The course costs $2,999 with the option for monthly instalments.\n",
            "- The course schedule is weekday evenings.\n",
            "\n",
            "Decisions:\n",
            "- You have expressed interest in the course and would like to schedule a trial session.\n",
            "- A 2-hour free trial session is available next week.\n",
            "\n",
            "Actionable Items:\n",
            "- Schedule a 2-hour free trial session for you next week.\n",
            "- Provide payment options for the course, including monthly instalments.\n",
            "- Confirm the course details with you, including the schedule and cost.\n",
            "----------------------------------------\n",
            "\n",
            "--- Final conversation state ---\n",
            "============================================================\n",
            "CONVERSATION HISTORY\n",
            "============================================================\n",
            "1. 📋 SYSTEM: [SUMMARY] **Summary:**\n",
            "\n",
            "Key Points:\n",
            "- The 6-month data science course covers Python, Machine Learning, statistics, and visualization.\n",
            "- The course costs $2,999 with the option for monthly instalments.\n",
            "- The course schedule is weekday evenings.\n",
            "\n",
            "Decisions:\n",
            "- You have expressed interest in the course and would like to schedule a trial session.\n",
            "- A 2-hour free trial session is available next week.\n",
            "\n",
            "Actionable Items:\n",
            "- Schedule a 2-hour free trial session for you next week.\n",
            "- Provide payment options for the course, including monthly instalments.\n",
            "- Confirm the course details with you, including the schedule and cost.\n",
            "   ⏰ 2025-09-14T10:50:13.458344\n",
            "----------------------------------------\n",
            "2. 🤖 ASSISTANT: Done. Please check your inbox.\n",
            "   ⏰ 2025-09-14T10:50:12.660241\n",
            "----------------------------------------\n",
            "3. 👤 USER: Also what's the refund policy?\n",
            "   ⏰ 2025-09-14T10:50:13.458727\n",
            "----------------------------------------\n",
            "4. 🤖 ASSISTANT: You can request refund within 14 days.\n",
            "   ⏰ 2025-09-14T10:50:13.458743\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: JSON schema + function-calling extraction (definition)"
      ],
      "metadata": {
        "id": "qhMa_-ML2PoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: JSON schema for extraction\n",
        "extraction_schema = {\n",
        "    \"name\": \"extract_user_information\",\n",
        "    \"description\": \"Extract user's name, email, phone, location and age from chat text.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\", \"description\": \"Full name of the user\"},\n",
        "            \"email\": {\"type\": \"string\", \"description\": \"Email address\"},\n",
        "            \"phone\": {\"type\": \"string\", \"description\": \"Phone number (any reasonable format)\"},\n",
        "            \"location\": {\"type\": \"string\", \"description\": \"City/state/country\"},\n",
        "            \"age\": {\"type\": \"integer\", \"description\": \"Age in years\"}\n",
        "        },\n",
        "        \"required\": []  # we'll validate and allow nulls for missing fields\n",
        "    }\n",
        "}\n",
        "print(\"✅ Extraction schema prepared.\")\n",
        "print(json.dumps(extraction_schema, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAu5uemJ2PT6",
        "outputId": "9d1b34ef-568d-401c-f680-e247e806689a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction schema prepared.\n",
            "{\n",
            "  \"name\": \"extract_user_information\",\n",
            "  \"description\": \"Extract user's name, email, phone, location and age from chat text.\",\n",
            "  \"parameters\": {\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "      \"name\": {\n",
            "        \"type\": \"string\",\n",
            "        \"description\": \"Full name of the user\"\n",
            "      },\n",
            "      \"email\": {\n",
            "        \"type\": \"string\",\n",
            "        \"description\": \"Email address\"\n",
            "      },\n",
            "      \"phone\": {\n",
            "        \"type\": \"string\",\n",
            "        \"description\": \"Phone number (any reasonable format)\"\n",
            "      },\n",
            "      \"location\": {\n",
            "        \"type\": \"string\",\n",
            "        \"description\": \"City/state/country\"\n",
            "      },\n",
            "      \"age\": {\n",
            "        \"type\": \"integer\",\n",
            "        \"description\": \"Age in years\"\n",
            "      }\n",
            "    },\n",
            "    \"required\": []\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: function-calling extraction & validator"
      ],
      "metadata": {
        "id": "xliuiqV02W6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: function-calling extraction + validation\n",
        "def extract_information_with_function_calling(client: OpenAI, chat_text: str, schema: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Uses the 'functions' parameter and requests a function call response from the model.\n",
        "    Returns a dict with success flag and data/raw_response.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"Extract these fields from the chat: name, email, phone, location, age. \"\n",
        "        \"Return JSON strictly matching the function schema. If a field is not present, return null for it.\\n\\n\"\n",
        "        f\"Chat:\\n{chat_text}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",   # active model for extraction too\n",
        "            messages=[{\"role\":\"user\", \"content\": prompt}],\n",
        "            functions=[schema],\n",
        "            function_call={\"name\": schema[\"name\"]},  # force the function call by name\n",
        "            temperature=0.0\n",
        "        )\n",
        "\n",
        "        # function call is expected to be in choices[0].message.function_call\n",
        "        choice_msg = resp.choices[0].message\n",
        "        function_call = getattr(choice_msg, \"function_call\", None)\n",
        "        if function_call and getattr(function_call, \"arguments\", None):\n",
        "            try:\n",
        "                extracted = json.loads(function_call.arguments)\n",
        "            except Exception:\n",
        "                # sometimes model returns invalid JSON; return raw string\n",
        "                extracted = {\"__raw_function_args\": function_call.arguments}\n",
        "            return {\"success\": True, \"data\": extracted, \"raw\": function_call.arguments}\n",
        "        else:\n",
        "            # fallback: model may return text; try to parse from content\n",
        "            text = choice_msg.content or \"\"\n",
        "            try:\n",
        "                parsed = json.loads(text.strip())\n",
        "                return {\"success\": True, \"data\": parsed, \"raw\": text}\n",
        "            except Exception:\n",
        "                return {\"success\": False, \"error\": \"No function call and could not parse text\", \"raw\": text}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e), \"raw\": None}\n",
        "\n",
        "\n",
        "def validate_extracted_data(data: dict, schema: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Basic validation: check types and presence. Returns dict with valid(bool), errors(list), warnings(list)\n",
        "    \"\"\"\n",
        "    res = {\"valid\": True, \"errors\": [], \"warnings\": []}\n",
        "    props = schema[\"parameters\"][\"properties\"]\n",
        "\n",
        "    # For required fields (none enforced here), we would check presence.\n",
        "    # Check types if present and non-null\n",
        "    for k, v in data.items():\n",
        "        if k in props and v is not None:\n",
        "            expected = props[k][\"type\"]\n",
        "            if expected == \"integer\":\n",
        "                if not isinstance(v, int):\n",
        "                    # try convert if string containing digits\n",
        "                    if isinstance(v, str) and v.isdigit():\n",
        "                        data[k] = int(v)\n",
        "                    else:\n",
        "                        res[\"warnings\"].append(f\"Field '{k}' expected integer, got {type(v).__name__}\")\n",
        "            elif expected == \"string\":\n",
        "                if not isinstance(v, str):\n",
        "                    res[\"warnings\"].append(f\"Field '{k}' expected string, got {type(v).__name__}\")\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "U1sGw7PB2Zsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2 demo: parse 3 sample chats and validate"
      ],
      "metadata": {
        "id": "Mlp10jyJ2c9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extraction_schema = {\n",
        "    \"name\": \"extract_user_information\",\n",
        "    \"description\": \"Extract user information from conversation text\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\", \"description\": \"User's full name\"},\n",
        "            \"email\": {\"type\": \"string\", \"description\": \"User's email address\"},\n",
        "            \"phone\": {\"type\": [\"string\", \"null\"], \"description\": \"User's phone number\"},\n",
        "            \"location\": {\"type\": [\"string\", \"null\"], \"description\": \"User's location\"},\n",
        "            \"age\": {\"type\": [\"integer\", \"null\"], \"description\": \"User's age in years\"}\n",
        "        },\n",
        "        \"required\": [\"name\", \"email\"]  # only mandatory fields\n",
        "    }\n",
        "}\n",
        "\n",
        "# Sample chat conversations\n",
        "sample_chats = [\n",
        "    {\n",
        "        \"id\": 1,\n",
        "        \"title\": \"Complete info\",\n",
        "        \"chat\": \"\"\"User: Hi, my name is John Smith. I'm 28 years old and I live in New York.\n",
        "Assistant: Welcome John! How can I help?\n",
        "User: You can reach me at john.smith@email.com or +1-555-123-4567.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 2,\n",
        "        \"title\": \"Partial info\",\n",
        "        \"chat\": \"\"\"User: Hello, I'm Sarah Johnson, applying for the job.\n",
        "Assistant: Thanks Sarah. Can you share email?\n",
        "User: Sure - sarah.j@techmail.com. I'm based in San Francisco.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 3,\n",
        "        \"title\": \"Mixed info\",\n",
        "        \"chat\": \"\"\"User: Hi, I'm Mike from Los Angeles. My email is mike.chen.la@gmail.com and my phone is 213-555-9876.\n",
        "Assistant: Thanks Mike. How old are you?\n",
        "User: I'm 45.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Extraction demonstration\n",
        "extraction_results = []\n",
        "for s in sample_chats:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Processing sample {s['id']}: {s['title']}\")\n",
        "    print(s['chat'])\n",
        "\n",
        "    # Extract info using Groq API\n",
        "    res = extract_information_with_function_calling(client, s['chat'], extraction_schema)\n",
        "\n",
        "    if res[\"success\"]:\n",
        "        extracted = res[\"data\"]\n",
        "        validation = validate_extracted_data(extracted, extraction_schema)\n",
        "        print(\"Extracted:\", extracted)\n",
        "        print(\"Validation:\", validation)\n",
        "        extraction_results.append({\"id\": s[\"id\"], \"extracted\": extracted, \"validation\": validation})\n",
        "    else:\n",
        "        print(\"Extraction failed:\", res.get(\"error\"))\n",
        "        print(\"Raw:\", res.get(\"raw_response\"))\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ Extraction demonstration completed for all samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYMLpxRG2f_R",
        "outputId": "bb412bf5-c8fd-4712-ccd1-2b1b868aa067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Processing sample 1: Complete info\n",
            "User: Hi, my name is John Smith. I'm 28 years old and I live in New York.\n",
            "Assistant: Welcome John! How can I help?\n",
            "User: You can reach me at john.smith@email.com or +1-555-123-4567.\n",
            "Extracted: {'age': 28, 'email': 'john.smith@email.com', 'location': 'New York', 'name': 'John Smith', 'phone': '+1-555-123-4567'}\n",
            "Validation: {'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "============================================================\n",
            "Processing sample 2: Partial info\n",
            "User: Hello, I'm Sarah Johnson, applying for the job.\n",
            "Assistant: Thanks Sarah. Can you share email?\n",
            "User: Sure - sarah.j@techmail.com. I'm based in San Francisco.\n",
            "Extracted: {'age': None, 'email': 'sarah.j@techmail.com', 'location': 'San Francisco', 'name': 'Sarah Johnson', 'phone': None}\n",
            "Validation: {'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "============================================================\n",
            "Processing sample 3: Mixed info\n",
            "User: Hi, I'm Mike from Los Angeles. My email is mike.chen.la@gmail.com and my phone is 213-555-9876.\n",
            "Assistant: Thanks Mike. How old are you?\n",
            "User: I'm 45.\n",
            "Extracted: {'age': 45, 'email': 'mike.chen.la@gmail.com', 'location': 'Los Angeles', 'name': 'Mike', 'phone': '213-555-9876'}\n",
            "Validation: {'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "============================================================\n",
            "✅ Extraction demonstration completed for all samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary & schema compliance metrics"
      ],
      "metadata": {
        "id": "fBrYABdt3MTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Summary metrics\n",
        "print(\"\\n=== Extraction Summary ===\")\n",
        "total = len(sample_chats)\n",
        "success_count = sum(1 for r in extraction_results if r[\"validation\"][\"valid\"] or r[\"extracted\"])\n",
        "print(f\"Total chats: {total}\")\n",
        "print(f\"Results obtained: {len(extraction_results)}\")\n",
        "print(\"Detailed per-chat results:\")\n",
        "for r in extraction_results:\n",
        "    print(f\"Chat {r['id']}: Extracted keys: {list(r['extracted'].keys())}, Valid: {r['validation']['valid']}, Warnings: {r['validation']['warnings']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzlxWEzA3M5g",
        "outputId": "d92b8010-071f-4f5d-9bdd-90696797806d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Extraction Summary ===\n",
            "Total chats: 3\n",
            "Results obtained: 3\n",
            "Detailed per-chat results:\n",
            "Chat 1: Extracted keys: ['age', 'email', 'location', 'name', 'phone'], Valid: True, Warnings: []\n",
            "Chat 2: Extracted keys: ['age', 'email', 'location', 'name', 'phone'], Valid: True, Warnings: []\n",
            "Chat 3: Extracted keys: ['age', 'email', 'location', 'name', 'phone'], Valid: True, Warnings: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integration test (combine summarization + extraction)"
      ],
      "metadata": {
        "id": "NpZ0QcT53Sba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Integrated end-to-end example\n",
        "def integrated_conversation_analysis(client, conversation_pairs, schema, conv_manager=None):\n",
        "    cm = conv_manager or ConversationManager(client)\n",
        "    for role, text in conversation_pairs:\n",
        "        cm.add_message(role, text)\n",
        "    # produce summary\n",
        "    summary = cm.summarize()\n",
        "    # build full conversation text for extraction\n",
        "    full_text = cm._conversation_text()\n",
        "    extraction = extract_information_with_function_calling(client, full_text, schema)\n",
        "    return {\"summary\": summary, \"extraction\": extraction, \"conversation_length\": len(cm.conversation_history)}\n",
        "\n",
        "# test\n",
        "test_conv = [\n",
        "    (\"user\", \"Hi, I'm Alex Rodriguez. I'm 29 and I live in Miami, Florida.\"),\n",
        "    (\"assistant\", \"Nice to meet you Alex.\"),\n",
        "    (\"user\", \"Contact me at alex.rodriguez@miami.edu or 305-555-0123.\")\n",
        "]\n",
        "\n",
        "integrated = integrated_conversation_analysis(client, test_conv, extraction_schema)\n",
        "print(\"\\n=== Integrated Result ===\")\n",
        "print(\"Summary:\\n\", integrated[\"summary\"])\n",
        "print(\"Extraction:\\n\", integrated[\"extraction\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_S0gLb83TKo",
        "outputId": "71cb39db-abce-4208-c398-7198a032a0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Integrated Result ===\n",
            "Summary:\n",
            " Unfortunately, there is no conversation to summarize. The conversation started with your introduction, but it ended abruptly without any further discussion. If you'd like to continue the conversation, I'd be happy to assist you with any questions or topics you'd like to discuss.\n",
            "Extraction:\n",
            " {'success': True, 'data': {'age': 29, 'email': 'alex.rodriguez@miami.edu', 'location': 'Miami, Florida', 'name': 'Alex Rodriguez', 'phone': '305-555-0123'}, 'raw': '{\"age\":29,\"email\":\"alex.rodriguez@miami.edu\",\"location\":\"Miami, Florida\",\"name\":\"Alex Rodriguez\",\"phone\":\"305-555-0123\"}'}\n"
          ]
        }
      ]
    }
  ]
}